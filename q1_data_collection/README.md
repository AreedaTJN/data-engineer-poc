# 1.1 OpenAlex Scraper
สคริปต์นี้ใช้สำหรับดึงผลงานวิจัยทั้งหมดที่เกี่ยวข้องกับสถาบัน Prince of Songkla University จาก OpenAlex API และบันทึกข้อมูลลงไฟล์ CSV
## วิธีใช้งาน
1. ติดตั้งไลบรารีที่จำเป็น  
   ```
   pip install requests pandas
   ```
2. รันสคริปต์  
   ```
   python openalex_scraper.py
   ```
ซึ่งอยู่ในโฟลเดอร์ q1_data_collection
3. ผลลัพธ์จะถูกบันทึกเป็นไฟล์ CSV ลงในโฟลเดอร์ data `data/openalex(PSU)_results_all.csv`
## รายละเอียดข้อมูลที่ดึง
- รหัสผลงาน (`id`)
- ชื่อเรื่อง (`title`)
- DOI
- ปีที่เผยแพร่ (`publication_year`)
- ประเภทผลงาน (`type`)
- จำนวนการอ้างอิง (`cited_by_count`)
- รายชื่อผู้แต่ง (`authors`)
- วารสารหรือแหล่งตีพิมพ์ (`host_venue`)
- สำนักพิมพ์ (`publisher`)
- สาขาวิชา (`concepts`)
## หมายเหตุ
- สามารถปรับจำนวนข้อมูลต่อหน้าได้ด้วย `per_page` (สูงสุด 200)
- สคริปต์จะดึงข้อมูลทุกหน้าโดยอัตโนมัติจนกว่าจะครบ

# 1.2 การประมวลผลข้อมูลจากไฟล์ Excel/CSV
สคริปต์นี้ใช้สำหรับรวมและคัดเลือกข้อมูลผลงานวิจัยจาก 3 แหล่ง ได้แก่ TCI, Scopus, และ Web of Science (ISI) โดยเลือกเฉพาะคอลัมน์ที่จำเป็น
## วิธีใช้งาน

1. ติดตั้งไลบรารีที่จำเป็น  
   ```
   pip install pandas
   ```

2. ตรวจสอบว่าไฟล์ CSV ดังต่อไปนี้อยู่ในโฟลเดอร์ `data`  
   - API_TCI_OUTPUT.csv  
   - API_SCOPUS_OUTPUT.csv  
   - API_ISI_OUTPUT.csv  

3. รันสคริปต์ในไฟล์ `csv_processor.ipynb` ด้วย VS Code การจัดการข้อมูลเบื้องต้น
- นำเข้าข้อมูลไฟล์ csv ของแต่ละแหล่ง (tci, scopus, wos)
- ตรวจสอบคอลัมน์ของแต่ละไฟล์และเลือกเอาเฉพาะคอลัมน์ที่สำคัญ
- เพิ่มคอลัมน์ SOURCE เพื่อให้ง่ายต่อการประมวลผลข้อมูลเพื่อนไทั้ง 3 ไฟล์มารวมกัน
- บันทึกทั้ง 3 ไฟล์ในโฟลเดอร์ data ของ q2_pipeline_db เพื่อนำไปประมวลผลขั้ตอนต่อไป

## ผลลัพธ์

- `tci_selected.csv` : ข้อมูลจาก TCI เฉพาะคอลัมน์ที่จำเป็น
- `scopus_selected.csv` : ข้อมูลจาก Scopus เฉพาะคอลัมน์ที่จำเป็น
- `wos_selected.csv` : ข้อมูลจาก Web of Science เฉพาะคอลัมน์ที่จำเป็น

## หมายเหตุ

- สามารถนำไฟล์ที่ได้ไปใช้วิเคราะห์ต่อ หรือเชื่อมต่อกับเครื่องมือ BI ได้ทันที
- หากต้องการปรับคอลัมน์ที่เลือก สามารถแก้ไขในโค้ด cell ที่เกี่ยวข้องใน `csv_processor.ipynb`

# 1.3 