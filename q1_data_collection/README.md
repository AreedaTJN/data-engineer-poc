# 1.1 OpenAlex Scraper
สคริปต์นี้ใช้สำหรับดึงผลงานวิจัยทั้งหมดที่เกี่ยวข้องกับสถาบัน Prince of Songkla University จาก OpenAlex API และบันทึกข้อมูลลงไฟล์ CSV
## วิธีใช้งาน
1. ติดตั้งไลบรารีที่จำเป็น  
   ```
   pip install requests pandas
   ```
2. รันสคริปต์  
   ```
   python openalex_scraper.py
   ```
ซึ่งอยู่ในโฟลเดอร์ q1_data_collection
3. ผลลัพธ์จะถูกบันทึกเป็นไฟล์ CSV ลงในโฟลเดอร์ data `data/openalex(PSU)_results_all.csv`
## รายละเอียดข้อมูลที่ดึง
- รหัสผลงาน (`id`)
- ชื่อเรื่อง (`title`)
- DOI
- ปีที่เผยแพร่ (`publication_year`)
- ประเภทผลงาน (`type`)
- จำนวนการอ้างอิง (`cited_by_count`)
- รายชื่อผู้แต่ง (`authors`)
- วารสารหรือแหล่งตีพิมพ์ (`host_venue`)
- สำนักพิมพ์ (`publisher`)
- สาขาวิชา (`concepts`)
## หมายเหตุ
- สามารถปรับจำนวนข้อมูลต่อหน้าได้ด้วย `per_page` (สูงสุด 200)
- สคริปต์จะดึงข้อมูลทุกหน้าโดยอัตโนมัติจนกว่าจะครบ

# 1.2 การประมวลผลข้อมูลจากไฟล์ Excel/CSV
สคริปต์นี้ใช้สำหรับรวมและคัดเลือกข้อมูลผลงานวิจัยจาก 3 แหล่ง ได้แก่ TCI, Scopus, และ Web of Science (ISI) โดยเลือกเฉพาะคอลัมน์ที่จำเป็น
## วิธีใช้งาน

1. ติดตั้งไลบรารีที่จำเป็น  
   ```
   pip install pandas
   ```

2. ตรวจสอบว่าไฟล์ CSV ดังต่อไปนี้อยู่ในโฟลเดอร์ `data`  
   - API_TCI_OUTPUT.csv  
   - API_SCOPUS_OUTPUT.csv  
   - API_ISI_OUTPUT.csv  

3. รันสคริปต์ในไฟล์ `csv_processor.ipynb` ด้วย Jupyter Notebook หรือ VS Code

## ขั้นตอนการทำงาน

- อ่านไฟล์ CSV จากแต่ละแหล่งข้อมูล
- เลือกเฉพาะคอลัมน์ที่จำเป็น เช่น ชื่อบทความ, ผู้แต่ง, ปี, วารสาร, เล่ม, ฉบับ, หน้า
- เพิ่มคอลัมน์ `SOURCE` เพื่อระบุแหล่งข้อมูล (TCI=0, SCOPUS=1, WOS=2)
- Export ข้อมูลที่เลือกแล้วออกเป็นไฟล์ CSV แยกตามแหล่งข้อมูล

## ผลลัพธ์

- `tci_selected.csv` : ข้อมูลจาก TCI เฉพาะคอลัมน์ที่จำเป็น
- `scopus_selected.csv` : ข้อมูลจาก Scopus เฉพาะคอลัมน์ที่จำเป็น
- `wos_selected.csv` : ข้อมูลจาก Web of Science เฉพาะคอลัมน์ที่จำเป็น

## หมายเหตุ

- สามารถนำไฟล์ที่ได้ไปใช้วิเคราะห์ต่อ หรือเชื่อมต่อกับเครื่องมือ BI ได้ทันที
- หากต้องการปรับคอลัมน์ที่เลือก สามารถแก้ไขในโค้ด cell ที่เกี่ยวข้องใน `csv_processor.ipynb`

# 1.3 